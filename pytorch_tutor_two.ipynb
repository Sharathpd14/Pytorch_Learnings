{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd\n",
    "\n",
    "    Autograd is a core component of pytorch that provides automatic differentiation for tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features\n",
    "x = torch.tensor(6.7)\n",
    "y = torch.tensor(0.0)\n",
    "\n",
    "w = torch.tensor(1.0)  # Weight\n",
    "b = torch.tensor(0.0) # Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Binary cross entropy\n",
    "def binary_cross_entrpy(prediction,target):\n",
    "    epsilon = 1e-8  # To prevent log(0)\n",
    "    prediction = torch.clamp(prediction,epsilon,1-epsilon)\n",
    "    return -(target * torch.log(prediction) + (1 - target) * torch.log(1-prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propogation\n",
    "z = w * x + b\n",
    "y_pred = torch.sigmoid(z)\n",
    "\n",
    "loss = binary_cross_entrpy(y_pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives:\n",
    "# 1. dL/d(y_pred): Loss with respect to the prediction (y_pred)\n",
    "dloss_dy_pred = (y_pred - y)/(y_pred*(1-y_pred))\n",
    "\n",
    "# 2. dy_pred/dz: Prediction (y_pred) with respect to z (sigmoid derivative)\n",
    "dy_pred_dz = y_pred * (1 - y_pred)\n",
    "\n",
    "# 3. dz/dw and dz/db: z with respect to w and b\n",
    "dz_dw = x  # dz/dw = x\n",
    "dz_db = 1  # dz/db = 1 (bias contributes directly to z)\n",
    "\n",
    "dL_dw = dloss_dy_pred * dy_pred_dz * dz_dw\n",
    "dL_db = dloss_dy_pred * dy_pred_dz * dz_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Gradient of loss w.r.t weight (dw): 6.691762447357178\n",
      "Manual Gradient of loss w.r.t bias (db): 0.998770534992218\n"
     ]
    }
   ],
   "source": [
    "print(f\"Manual Gradient of loss w.r.t weight (dw): {dL_dw}\")\n",
    "print(f\"Manual Gradient of loss w.r.t bias (db): {dL_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6918)\n",
      "tensor(0.9988)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(6.7)\n",
    "y = torch.tensor(0.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "w\n",
    "\n",
    "b\n",
    "\n",
    "z = w*x + b\n",
    "z\n",
    "\n",
    "y_pred = torch.sigmoid(z)\n",
    "y_pred\n",
    "\n",
    "loss = binary_cross_entrpy(y_pred, y)\n",
    "loss\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(w.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 2.0000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "x\n",
    "\n",
    "y = (x**2).mean()\n",
    "y\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing grad\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "y\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.zero_>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "y\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad\n",
    "\n",
    "# option 1 - requires_grad_(False)\n",
    "# option 2 - detach()\n",
    "# option 3 - torch.no_grad()\n",
    "\n",
    "x.requires_grad_(False)\n",
    "\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "y\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad\n",
    "\n",
    "# option 1 - requires_grad_(False)\n",
    "# option 2 - detach()\n",
    "# option 3 - torch.no_grad()\n",
    "\n",
    "x.requires_grad_(False)\n",
    "\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x\n",
    "\n",
    "z = x.detach()\n",
    "z\n",
    "\n",
    "y = x ** 2\n",
    "\n",
    "y\n",
    "\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "x\n",
    "\n",
    "y = x ** 2\n",
    "\n",
    "y\n",
    "\n",
    "\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ypt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
